{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/konstantin/.local/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "%run __init__.py\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select pairs of images to be examined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "log_path = \"/home/konstantin/personal/Summertime/Net/runs/NetVGG_v2/7_ems=0.389194_3.0_megadepth_px_log.csv\"\n",
    "log = pd.read_csv(log_path, index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene_name</th>\n",
       "      <th>image1_name</th>\n",
       "      <th>image2_name</th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>rep</th>\n",
       "      <th>rep_matches</th>\n",
       "      <th>rep_vis_gt_matches</th>\n",
       "      <th>ms</th>\n",
       "      <th>ms_matches</th>\n",
       "      <th>ms_vis_gt_matches</th>\n",
       "      <th>mma</th>\n",
       "      <th>mma_matches</th>\n",
       "      <th>mma_vis_mutual_matches</th>\n",
       "      <th>ems</th>\n",
       "      <th>ems_matches</th>\n",
       "      <th>ems_vis_gt_matches</th>\n",
       "      <th>r_err</th>\n",
       "      <th>t_err</th>\n",
       "      <th>num_inl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2876158350_e9ee1feeab_o.jpg</td>\n",
       "      <td>2753237714_a4bc02bbfb_o.jpg</td>\n",
       "      <td>763</td>\n",
       "      <td>280</td>\n",
       "      <td>0.965368</td>\n",
       "      <td>223.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>6.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>6.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>175.645981</td>\n",
       "      <td>154.150391</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>2682477527_1f5e69625e_o.jpg</td>\n",
       "      <td>3775553693_a1c57a56d2_o.jpg</td>\n",
       "      <td>2984</td>\n",
       "      <td>1223</td>\n",
       "      <td>1.039474</td>\n",
       "      <td>79.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>3.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>72.301514</td>\n",
       "      <td>30.899347</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>3442164011_022e239e78_o.jpg</td>\n",
       "      <td>3554143874_0056473012_o.jpg</td>\n",
       "      <td>1324</td>\n",
       "      <td>2823</td>\n",
       "      <td>0.879518</td>\n",
       "      <td>219.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>9.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>9.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.036145</td>\n",
       "      <td>9.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>43.328857</td>\n",
       "      <td>107.702774</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>2876158350_e9ee1feeab_o.jpg</td>\n",
       "      <td>2929143119_74f20fb006_o.jpg</td>\n",
       "      <td>763</td>\n",
       "      <td>2703</td>\n",
       "      <td>0.713881</td>\n",
       "      <td>252.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.067989</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>0.083624</td>\n",
       "      <td>24.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>0.067989</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>34.823158</td>\n",
       "      <td>22.624496</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>3442164011_022e239e78_o.jpg</td>\n",
       "      <td>425274860_ca81ab5bbd_o.jpg</td>\n",
       "      <td>1324</td>\n",
       "      <td>295</td>\n",
       "      <td>1.036697</td>\n",
       "      <td>226.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>5.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.015924</td>\n",
       "      <td>5.0</td>\n",
       "      <td>314.0</td>\n",
       "      <td>0.022936</td>\n",
       "      <td>5.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>42.473690</td>\n",
       "      <td>61.276321</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>237</td>\n",
       "      <td>2937319332_f3c3283b6b_o.jpg</td>\n",
       "      <td>1396882091_83bc0bc087_o.jpg</td>\n",
       "      <td>1657</td>\n",
       "      <td>3025</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>66.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>5.0</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>38.153999</td>\n",
       "      <td>47.648399</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>237</td>\n",
       "      <td>2936464980_a483710cd4_o.jpg</td>\n",
       "      <td>15635370597_71a79f2806_o.jpg</td>\n",
       "      <td>914</td>\n",
       "      <td>240</td>\n",
       "      <td>0.515385</td>\n",
       "      <td>67.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.430769</td>\n",
       "      <td>56.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>56.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>48.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>32.827248</td>\n",
       "      <td>66.494781</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>237</td>\n",
       "      <td>4919768603_7ff39960c0_o.jpg</td>\n",
       "      <td>6129982612_5580115a30_b.jpg</td>\n",
       "      <td>2007</td>\n",
       "      <td>2198</td>\n",
       "      <td>0.141935</td>\n",
       "      <td>44.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>179.332947</td>\n",
       "      <td>129.615005</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>237</td>\n",
       "      <td>3780773211_86b385abdb_o.jpg</td>\n",
       "      <td>6059675990_58e60aca40_o.jpg</td>\n",
       "      <td>926</td>\n",
       "      <td>1622</td>\n",
       "      <td>0.369231</td>\n",
       "      <td>120.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>8.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>8.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>7.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>100.897942</td>\n",
       "      <td>139.675781</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>237</td>\n",
       "      <td>15509788303_6410332b88_o.jpg</td>\n",
       "      <td>8322376726_0a4abedf8c_b.jpg</td>\n",
       "      <td>140</td>\n",
       "      <td>386</td>\n",
       "      <td>0.511364</td>\n",
       "      <td>90.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>9.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.028391</td>\n",
       "      <td>9.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>9.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>152.920380</td>\n",
       "      <td>113.505959</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      scene_name                   image1_name                   image2_name  \\\n",
       "14             1   2876158350_e9ee1feeab_o.jpg   2753237714_a4bc02bbfb_o.jpg   \n",
       "34             1   2682477527_1f5e69625e_o.jpg   3775553693_a1c57a56d2_o.jpg   \n",
       "61             1   3442164011_022e239e78_o.jpg   3554143874_0056473012_o.jpg   \n",
       "67             1   2876158350_e9ee1feeab_o.jpg   2929143119_74f20fb006_o.jpg   \n",
       "89             1   3442164011_022e239e78_o.jpg    425274860_ca81ab5bbd_o.jpg   \n",
       "...          ...                           ...                           ...   \n",
       "1541         237   2937319332_f3c3283b6b_o.jpg   1396882091_83bc0bc087_o.jpg   \n",
       "1544         237   2936464980_a483710cd4_o.jpg  15635370597_71a79f2806_o.jpg   \n",
       "1548         237   4919768603_7ff39960c0_o.jpg   6129982612_5580115a30_b.jpg   \n",
       "1576         237   3780773211_86b385abdb_o.jpg   6059675990_58e60aca40_o.jpg   \n",
       "1578         237  15509788303_6410332b88_o.jpg   8322376726_0a4abedf8c_b.jpg   \n",
       "\n",
       "       id1   id2       rep  rep_matches  rep_vis_gt_matches        ms  \\\n",
       "14     763   280  0.965368        223.0               231.0  0.025974   \n",
       "34    2984  1223  1.039474         79.0                76.0  0.039474   \n",
       "61    1324  2823  0.879518        219.0               249.0  0.036145   \n",
       "67     763  2703  0.713881        252.0               353.0  0.067989   \n",
       "89    1324   295  1.036697        226.0               218.0  0.022936   \n",
       "...    ...   ...       ...          ...                 ...       ...   \n",
       "1541  1657  3025  0.653465         66.0               101.0  0.049505   \n",
       "1544   914   240  0.515385         67.0               130.0  0.430769   \n",
       "1548  2007  2198  0.141935         44.0               310.0  0.000000   \n",
       "1576   926  1622  0.369231        120.0               325.0  0.024615   \n",
       "1578   140   386  0.511364         90.0               176.0  0.051136   \n",
       "\n",
       "      ms_matches  ms_vis_gt_matches       mma  mma_matches  \\\n",
       "14           6.0              231.0  0.021429          6.0   \n",
       "34           3.0               76.0  0.009346          3.0   \n",
       "61           9.0              249.0  0.029508          9.0   \n",
       "67          24.0              353.0  0.083624         24.0   \n",
       "89           5.0              218.0  0.015924          5.0   \n",
       "...          ...                ...       ...          ...   \n",
       "1541         5.0              101.0  0.011682          5.0   \n",
       "1544        56.0              130.0  0.148148         56.0   \n",
       "1548         0.0              310.0  0.000000          0.0   \n",
       "1576         8.0              325.0  0.020619          8.0   \n",
       "1578         9.0              176.0  0.028391          9.0   \n",
       "\n",
       "      mma_vis_mutual_matches       ems  ems_matches  ems_vis_gt_matches  \\\n",
       "14                     280.0  0.025974          6.0               231.0   \n",
       "34                     321.0  0.039474          3.0                76.0   \n",
       "61                     305.0  0.036145          9.0               249.0   \n",
       "67                     287.0  0.067989         24.0               353.0   \n",
       "89                     314.0  0.022936          5.0               218.0   \n",
       "...                      ...       ...          ...                 ...   \n",
       "1541                   428.0  0.049505          5.0               101.0   \n",
       "1544                   378.0  0.369231         48.0               130.0   \n",
       "1548                   325.0  0.000000          0.0               310.0   \n",
       "1576                   388.0  0.021538          7.0               325.0   \n",
       "1578                   317.0  0.051136          9.0               176.0   \n",
       "\n",
       "           r_err       t_err  num_inl  \n",
       "14    175.645981  154.150391        9  \n",
       "34     72.301514   30.899347        9  \n",
       "61     43.328857  107.702774       11  \n",
       "67     34.823158   22.624496       24  \n",
       "89     42.473690   61.276321        8  \n",
       "...          ...         ...      ...  \n",
       "1541   38.153999   47.648399       10  \n",
       "1544   32.827248   66.494781       62  \n",
       "1548  179.332947  129.615005       35  \n",
       "1576  100.897942  139.675781       26  \n",
       "1578  152.920380  113.505959       16  \n",
       "\n",
       "[111 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log[(log['r_err'] < 2) & (log['t_err'] < 10)]\n",
    "log[(log['r_err'] > 20) & (log['t_err'] > 20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations_path = \"/home/konstantin/datasets/MegaDepthDataset/SceneInfo/annotations.csv\"\n",
    "# # selected_scenes = log[log['num_inl'] * 0.9 < log['num_ep_inl']]\n",
    "# selected_scenes = log[log['r_err'].gt(pose_thresh[thresh_id])]\n",
    "# create_log_annotations(selected_scenes, annotations_path, log_path, f\"gt{pose_thresh[thresh_id]}correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_scenes[selected_scenes['image1_name'] == \"3512952364_dc5151147b_o.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_scenes[selected_scenes['image1_name'] == '8791638021_2b87e87140_o.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_scenes = log[log['r_err'].lt(pose_thresh[thresh_id])]\n",
    "# correct_scenes = correct_scenes[correct_scenes['image1_name']=='2159797018_f3f75d3ef5_o.jpg']\n",
    "# correct_scenes\n",
    "\n",
    "# selected_scenes[selected_scenes['image1_name'] == '3512952364_dc5151147b_o.jpg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment on selected pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "\t         grid_size : 8\n",
      "\t   descriptor_size : 64\n",
      "\t   nms_kernel_size : 15\n",
      "\t          detailed : True\n",
      "\t        nms_thresh : 0.0\n",
      "\t        nms_k_size : 5\n",
      "\t             top_k : 512\n",
      "\t   checkpoint_name : ['154_emms=27.04305']\n",
      "criterion\n",
      "\t        des_lambda : 1\n",
      "\t            margin : 1\n",
      "\t        det_lambda : 120\n",
      "\t      gauss_k_size : 15\n",
      "\t       gauss_sigma : 0.5\n",
      "dataset\n",
      "\tanalyze\n",
      "\t\tmegadepth\n",
      "\t\t\t      dataset_root : /home/konstantin/datasets/MegaDepthDataset\n",
      "\t\t\t   scene_info_root : /home/konstantin/datasets/MegaDepthDataset/SceneInfo\n",
      "\t\t\t          csv_path : /home/konstantin/personal/Summertime/Net/runs/NetVGG_v2/gt5correct.csv\n",
      "\t\t\t            height : 480\n",
      "\t\t\t             width : 640\n",
      "\t\t\t           sources : True\n",
      "loader\n",
      "\tanalyze\n",
      "\t\t        batch_size : 3\n",
      "\t\t       num_samples : 3\n",
      "\t\t           shuffle : False\n",
      "\t\t       num_workers : 0\n",
      "metric\n",
      "\tanalyze\n",
      "\t\t         px_thresh : [1.0, 3.0, 5.0]\n",
      "\t\t         ep_thresh : 3.0\n",
      "\t\t      r_err_thresh : 2.0\n",
      "\t\t      t_err_thresh : 10.0\n",
      "\t\t        dd_measure : 0\n",
      "experiment\n",
      "\t        num_epochs : 1\n",
      "\t     return_output : True\n"
     ]
    }
   ],
   "source": [
    "model_config_path = '../configs/model.yaml'\n",
    "mode_config_path = '../configs/analyze.yaml'\n",
    "\n",
    "model_name = 'NetVGG'\n",
    "model_version = 'v1'\n",
    "\n",
    "mode = 'analyze'\n",
    "dataset = 'megadepth'\n",
    "gpu = '2'\n",
    "\n",
    "experiment = create_experiment(model_config_path, mode_config_path, model_name, model_version,\n",
    "                               mode, dataset, gpu, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch, endpoint), metrics = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_name = batch.get(du.IMAGE1_NAME)\n",
    "image2_name = batch.get(du.IMAGE2_NAME)\n",
    "\n",
    "image1 = batch.get(du.IMAGE1)\n",
    "image2 = batch.get(du.IMAGE2)\n",
    "\n",
    "depth1 = batch.get(du.DEPTH1)\n",
    "depth2 = batch.get(du.DEPTH2)\n",
    "\n",
    "desc1 = endpoint[eu.DESC1]\n",
    "desc2 = endpoint[eu.DESC2]\n",
    "\n",
    "score1 = endpoint[eu.SCORE1]\n",
    "score2 = endpoint[eu.SCORE2]\n",
    "\n",
    "sal_score1 = endpoint[eu.SAL_SCORE1]\n",
    "sal_score2 = endpoint[eu.SAL_SCORE2]\n",
    "\n",
    "conf_score1 = endpoint[eu.CONF_SCORE1]\n",
    "conf_score2 = endpoint[eu.CONF_SCORE2]\n",
    "\n",
    "intrinsics1 = batch.get(du.INTRINSICS1)\n",
    "intrinsics2 = batch.get(du.INTRINSICS2)\n",
    "\n",
    "extrinsics1 = batch.get(du.EXTRINSICS1)\n",
    "extrinsics2 = batch.get(du.EXTRINSICS2)\n",
    "\n",
    "shift_scale1 = batch.get(du.SHIFT_SCALE1)\n",
    "shift_scale2 = batch.get(du.SHIFT_SCALE2)\n",
    "\n",
    "kp1 = endpoint[eu.KP1]\n",
    "kp2 = endpoint[eu.KP2]\n",
    "\n",
    "w_kp1 = endpoint[eu.W_KP1]\n",
    "w_kp2 = endpoint[eu.W_KP2]\n",
    "\n",
    "w_vis_kp1_mask = endpoint[eu.W_VIS_KP1_MASK]\n",
    "w_vis_kp2_mask = endpoint[eu.W_VIS_KP2_MASK]\n",
    "\n",
    "kp1_desc = endpoint[eu.KP1_DESC]\n",
    "kp2_desc = endpoint[eu.KP2_DESC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image1_name)\n",
    "# print(image2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px_thresh_id = 1\n",
    "# batch_id = 1\n",
    "\n",
    "# px_thresh = torch.tensor(experiment.metric_config[exp.ANALYZE][exp.PX_THRESH]).to(experiment.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_rel_pose, est_inl_mask, gt_matches_mask, nn_kp_ids1 = \\\n",
    "#                 estimate_rel_poses_gt_opengv(kp1, endpoint[n.W_KP1], kp2, endpoint[n.W_KP2],\n",
    "#                                              endpoint[n.W_VIS_KP1_MASK], endpoint[n.W_VIS_KP2_MASK],\n",
    "#                                              intrinsics1, intrinsics2,\n",
    "#                                              shift_scale1, shift_scale2,\n",
    "#                                              px_thresh, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_s_image1 = torch2cv(s_image1[batch_id])\n",
    "# cv_s_image2 = torch2cv(s_image2[batch_id])\n",
    "\n",
    "# cv_inl_opengv = draw_cv_matches(cv_s_image1, cv_s_image2, kp1[batch_id], kp2[batch_id], \n",
    "#                                 nn_kp_ids1[batch_id], est_inl_mask[px_thresh_id][batch_id])\n",
    "\n",
    "# inl_opengv = {f\"OpenGV inlier for {px_thresh[px_thresh_id]}px threshold\": cv_inl_opengv}\n",
    "\n",
    "# plot_figures(inl_opengv, 1, 1, (18, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Net.source.utils.math_utils import create_coordinates_grid\n",
    "# from Net.source.utils.projective_transform_utils import warp_coordinates_grid_r3, warp_image_r3\n",
    "# from Net.source.utils.math_utils import to_original, compose_gt_fundamental, epipolar_distance\n",
    "\n",
    "# image1 = batch.get(d.IMAGE1)\n",
    "# image2 = batch.get(d.IMAGE2)\n",
    "\n",
    "# depth1 = batch.get(d.DEPTH1)\n",
    "# depth2 = batch.get(d.DEPTH2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1 = create_coordinates_grid(image1.shape).to(depth1.device)\n",
    "# w_grid1, w_depth_mask1 = warp_coordinates_grid_r3(grid1, depth1, intrinsics1, extrinsics1, shift_scale1, \n",
    "#                                                   depth2, intrinsics2, extrinsics2, shift_scale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 195., 132.\n",
    "# 195.6987, 199.8134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid1[0][132, 195])\n",
    "# print(w_grid1[0][132, 195])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o_grid1, o_w_grid1 = to_original(grid1.view(3, -1, 2)[..., [1,0]], \n",
    "#                                  w_grid1.view(3, -1, 2)[..., [1,0]], shift_scale1, shift_scale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_grid1[0][132, 195, 0] / shift_scale2[0, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(o_grid1.view(3, 480, 640, 2)[0, 132, 195, :])\n",
    "# print(o_w_grid1.view(3, 480, 640, 2)[0, 132, 195, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 341.8594, 415.5250\n",
    "# 321.9855, 666.0447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(shift_scale1)\n",
    "# print(shift_scale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F_gt = compose_gt_fundamental(intrinsics1, intrinsics2, \\\n",
    "#                               extrinsics1, extrinsics2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 = torch.tensor(np.array([341.879, 416.207])).unsqueeze(0).float().to(F_gt.device)\n",
    "# p2 = torch.tensor(np.array([321.989, 666.581])).unsqueeze(0).float().to(F_gt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epipolar_distance(p1, p2, F_gt[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1[:, 0] = p1[:, 0] * shift_scale1[0, 3]\n",
    "# p1[:, 1] = p1[:, 1] * shift_scale1[0, 2]\n",
    "\n",
    "# p1 = p1.long().float().view(1, 1, 1, 2)\n",
    "\n",
    "# print(p1)\n",
    "\n",
    "# w_grid1, w_depth_mask1 = warp_coordinates_grid_r3(p1, \n",
    "#                                                   depth1[0].unsqueeze(0), \n",
    "#                                                   intrinsics1[0].unsqueeze(0),\n",
    "#                                                   extrinsics1[0].unsqueeze(0), \n",
    "#                                                   shift_scale1[0].unsqueeze(0), \n",
    "#                                                   depth2[0].unsqueeze(0),\n",
    "#                                                   intrinsics2[0].unsqueeze(0),\n",
    "#                                                   extrinsics2[0].unsqueeze(0), \n",
    "#                                                   shift_scale2[0].unsqueeze(0))\n",
    "\n",
    "# print(w_grid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p2[:, 0] = p2[:, 0] * shift_scale2[0, 3]\n",
    "# p2[:, 1] = p2[:, 1] * shift_scale2[0, 2]\n",
    "\n",
    "# p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1 = p1.view(1, 2)\n",
    "# p2 = w_grid1.view(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p1[:, 0] = p1[:, 0] / shift_scale1[0, 3]\n",
    "# p1[:, 1] = p1[:, 1] / shift_scale1[0, 2]\n",
    "\n",
    "\n",
    "# p2[:, 0] = p2[:, 0] / shift_scale2[0, 3]\n",
    "# p2[:, 1] = p2[:, 1] / shift_scale2[0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(p1)\n",
    "# print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 341.8594, 415.5250\n",
    "# 343.0843, 628.9961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epipolar_distance(p1, p2, F_gt[0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = epipolar_distance(o_grid1, o_w_grid1, F_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist.min(dim=-1)[0][batch_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_map = torch.exp(- dist.view(3, 1, 480, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 64147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_h_map = torch2cv(h_map[batch_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_figures({\"cv_h_map\": cv_h_map}, 1, 1, (18, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Net.source.datasets.utils import load_depth\n",
    "\n",
    "# im1 = cv2.imread(\"/home/konstantin/datasets/MegaDepthDataset/Undistorted_SfM/0200/images/14710405830_1b6ed8baa1_o.jpg\")\n",
    "# im2 = cv2.imread(\"/home/konstantin/datasets/MegaDepthDataset/Undistorted_SfM/0200/images/865078244_bb2560a098_o.jpg\")\n",
    "\n",
    "# dp1 = load_depth(\"/home/konstantin/datasets/MegaDepthDataset/MegaDepth_v1/0200/dense0/depths/14710405830_1b6ed8baa1_o.h5\")\n",
    "# dp2 = load_depth(\"/home/konstantin/datasets/MegaDepthDataset/MegaDepth_v1/0200/dense0/depths/865078244_bb2560a098_o.h5\")\n",
    "\n",
    "# scene_info_root = \"/home/konstantin/datasets/MegaDepthDataset/SceneInfo\"\n",
    "# scene_path = os.path.join(scene_info_root, \"0200.npz\")\n",
    "# scene_info = np.load(scene_path, allow_pickle=True)\n",
    "\n",
    "# max_scale_ratio = np.inf\n",
    "    \n",
    "# points3D_id_to_2D = scene_info['points3D_id_to_2D']\n",
    "# points3D_id_to_ndepth = scene_info['points3D_id_to_ndepth']\n",
    "    \n",
    "# idx1, idx2 = 447,984\n",
    "    \n",
    "# proj_idx1 = points3D_id_to_2D[idx1]\n",
    "# proj_idx2 = points3D_id_to_2D[idx2]\n",
    "\n",
    "# matches = np.array(list(proj_idx1.keys() & proj_idx2.keys()))\n",
    "\n",
    "# depth_idx1 = points3D_id_to_ndepth[idx1]\n",
    "# depth_idx2 = points3D_id_to_ndepth[idx2]\n",
    "\n",
    "# matches_nd1 = np.array([depth_idx1[match] for match in matches])\n",
    "# matches_nd2 = np.array([depth_idx2[match] for match in matches])\n",
    "\n",
    "# scale_ratio = np.maximum(matches_nd1 / matches_nd2, matches_nd2 / matches_nd1)\n",
    "\n",
    "# matches = matches[np.where(scale_ratio <= max_scale_ratio)[0]]\n",
    "\n",
    "# sift_kp1 = np.array([proj_idx1[match] for match in matches])\n",
    "# sift_kp2 = np.array([proj_idx2[match] for match in matches])\n",
    "\n",
    "\n",
    "# im1 = draw_cv_keypoints(im1, sift_kp1[:, [1, 0]], (0, 255, 0))\n",
    "# im2 = draw_cv_keypoints(im2, sift_kp2[:, [1, 0]], (0, 255, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift_kp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_figures({\"im1\": im1,\n",
    "#               \"im2\": im2}, 1, 2, (18, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = epipolar_distance(torch.tensor(sift_kp1).float().unsqueeze(0), \n",
    "#                          torch.tensor(sift_kp2).float().unsqueeze(0),\n",
    "#                          F_gt[batch_id].unsqueeze(0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid1 = create_coordinates_grid((1, 1, 1178, 1600)).to(depth1.device)\n",
    "# w_grid1, w_depth_mask1 = warp_coordinates_grid_r3(grid1, \n",
    "#                                                   torch.tensor(dp1).unsqueeze(0).unsqueeze(0).to(F_gt.device), \n",
    "#                                                   intrinsics1[batch_id].unsqueeze(0),\n",
    "#                                                   extrinsics1[batch_id].unsqueeze(0), \n",
    "#                                                   torch.tensor([0, 0, 1.0, 1.0]).to(F_gt.device).unsqueeze(0), \n",
    "#                                                   torch.tensor(dp2).unsqueeze(0).unsqueeze(0).to(F_gt.device),\n",
    "#                                                   intrinsics2[batch_id].unsqueeze(0),\n",
    "#                                                   extrinsics2[batch_id].unsqueeze(0), \n",
    "#                                                   torch.tensor([0, 0, 1.0, 1.0]).to(F_gt.device).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid1.view(1, -1, 2)[0, 64147])\n",
    "# print(w_grid1.view(1, -1, 2)[0, 64147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = epipolar_distance(grid1, w_grid1, F_gt[batch_id].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist.view(1, -1)[0, 64147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_map = torch.exp(-dist.view(1, 1, 1178, 1600))\n",
    "# cv_h_map = torch2cv(h_map[0] * w_depth_mask1[0].float())\n",
    "# plot_figures({\"cv_h_map\": cv_h_map}, 1, 1, (18, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene_info_root = \"/home/konstantin/datasets/MegaDepthDataset/SceneInfo\"\n",
    "# ep_thresh = 3.0\n",
    "\n",
    "# sift_log = [{} for _ in range(len(px_thresh))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_scale_ratio = np.inf\n",
    "\n",
    "# for _, row in log.iterrows():\n",
    "#     scene_name = str(row[d.SCENE_NAME]).zfill(4)\n",
    "#     scene_path = os.path.join(scene_info_root, f\"{scene_name}.npz\")\n",
    "#     scene_info = np.load(scene_path, allow_pickle=True)\n",
    "    \n",
    "#     intrinsics1 = scene_info['intrinsics'][row[d.ID1]]\n",
    "#     intrinsics2 = scene_info['intrinsics'][row[d.ID2]]\n",
    "    \n",
    "#     extrinsics1 = scene_info['poses'][row[d.ID1]]\n",
    "#     extrinsics2 = scene_info['poses'][row[d.ID2]]\n",
    "    \n",
    "#     points3D_id_to_2D = scene_info['points3D_id_to_2D']\n",
    "#     points3D_id_to_ndepth = scene_info['points3D_id_to_ndepth']\n",
    "    \n",
    "#     idx1, idx2 = row[d.ID1], row[d.ID2]\n",
    "    \n",
    "#     proj_idx1 = points3D_id_to_2D[idx1]\n",
    "#     proj_idx2 = points3D_id_to_2D[idx2]\n",
    "\n",
    "#     matches = np.array(list(proj_idx1.keys() & proj_idx2.keys()))\n",
    "    \n",
    "#     depth_idx1 = points3D_id_to_ndepth[idx1]\n",
    "#     depth_idx2 = points3D_id_to_ndepth[idx2]\n",
    "\n",
    "#     matches_nd1 = np.array([depth_idx1[match] for match in matches])\n",
    "#     matches_nd2 = np.array([depth_idx2[match] for match in matches])\n",
    "\n",
    "#     scale_ratio = np.maximum(matches_nd1 / matches_nd2, matches_nd2 / matches_nd1)\n",
    "\n",
    "#     matches = matches[np.where(scale_ratio <= max_scale_ratio)[0]]\n",
    "\n",
    "#     sift_kp1 = np.array([proj_idx1[match] for match in matches])\n",
    "#     sift_kp2 = np.array([proj_idx2[match] for match in matches])\n",
    "    \n",
    "#     est_rel_pose, est_inl_mask = estimate_rel_poses_sift_opengv(sift_kp1, sift_kp2, intrinsics1, intrinsics2, px_thresh.cpu().numpy())\n",
    "    \n",
    "#     gt_rel_pose = get_gt_rel_poses(torch.tensor(extrinsics1).unsqueeze(0), torch.tensor(extrinsics2).unsqueeze(0))\n",
    "    \n",
    "#     F_gt = compose_gt_fundamental(torch.tensor(intrinsics1).unsqueeze(0).float(), torch.tensor(intrinsics2).unsqueeze(0).float(), \\\n",
    "#                                   torch.tensor(extrinsics1).unsqueeze(0).float(), torch.tensor(extrinsics2).unsqueeze(0).float())\n",
    "    \n",
    "#     detailed_pose = [{} for _ in range(px_thresh.shape[0])]\n",
    "    \n",
    "#     for i in range(px_thresh.shape[0]):\n",
    "#         detailed_pose[i][d.SCENE_NAME] = row[d.SCENE_NAME]\n",
    "        \n",
    "#         detailed_pose[i][d.IMAGE1_NAME] = row[d.IMAGE1_NAME]\n",
    "#         detailed_pose[i][d.IMAGE2_NAME] = row[d.IMAGE2_NAME]\n",
    "        \n",
    "#         detailed_pose[i][d.ID1] = row[d.ID1]\n",
    "#         detailed_pose[i][d.ID2] = row[d.ID2]\n",
    "        \n",
    "#         detailed_pose[i][ev.R_ERR] = angle_mat(est_rel_pose[i, :3, :3].unsqueeze(0), gt_rel_pose[:, :3, :3])\n",
    "#         detailed_pose[i][ev.T_ERR] = angle_vec(est_rel_pose[i, :3, 3].unsqueeze(0), gt_rel_pose[:, :3, 3])\n",
    "#         detailed_pose[i][ev.NUM_INL] = est_inl_mask[i].sum(dim=-1).unsqueeze(0)\n",
    "        \n",
    "#         i_mask = est_inl_mask[i]\n",
    "#         ep_dist = epipolar_distance(torch.tensor(sift_kp1[i_mask]).unsqueeze(0).float(), \n",
    "#                                     torch.tensor(sift_kp2[i_mask]).unsqueeze(0).float(), F_gt)\n",
    "        \n",
    "#         detailed_pose[i][ev.NUM_EP_INL] = (ep_dist < ep_thresh).sum().unsqueeze(0)\n",
    "        \n",
    "        \n",
    "#     for i in range(len(px_thresh)):\n",
    "#         for _k, _v in detailed_pose[i].items():\n",
    "#             if _k in sift_log[i]:\n",
    "#                 sift_log[i][_k].append(_v)\n",
    "#             else:\n",
    "#                 sift_log[i][_k] = [_v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "\n",
    "# for i in range(len(px_thresh)):\n",
    "#     for _k, _v in sift_log[i].items():\n",
    "#         if torch.is_tensor(sift_log[i][_k][0]):\n",
    "#             sift_log[i][_k] = torch.cat(sift_log[i][_k], dim=0).cpu().numpy().tolist()\n",
    "\n",
    "#         elif isinstance(sift_log[i][_k][0], list):\n",
    "#             sift_log[i][_k] = list(itertools.chain(*sift_log[i][_k]))\n",
    "    \n",
    "#     results.append(pd.DataFrame(data=sift_log[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log['r_err'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[1]['r_err'].le(pose_thresh).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log['r_err'].le(pose_thresh).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# thres=np.arange(5, 21, 5)\n",
    "\n",
    "# pass_ratio = [np.sum(errs < th) / len(errs) for th in thres ]\n",
    "# mAP = {th:np.mean(pass_ratio[:i+1]) for i, th in enumerate(thres)}\n",
    "# mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# from Net.source.utils.eval_utils import LOG\n",
    "# file_path = \"/home/konstantin/personal/Summertime/Net/runs/NetVGG_v2/34_avg_ms_mma=0.4495938.pkl\"\n",
    "\n",
    "# with open(file_path, 'rb') as f:\n",
    "#     metrics = pickle.load(f)\n",
    "\n",
    "# log = metrics[LOG]\n",
    "\n",
    "# import os\n",
    "\n",
    "# scene_pair_paths = []\n",
    "\n",
    "# def compose_path(scene_name, im_name):\n",
    "#     root = \"/home/konstantin/datasets/MegaDepthDataset/MegaDepth_v1_SfM\"\n",
    "#     return os.path.join(root, scene_name, \"images\", im_name)\n",
    "\n",
    "# for scene_name, im1_name, im2_name, _, _ in log.filtered_data:\n",
    "#     path1 = compose_path(scene_name, im1_name)\n",
    "#     path2 = compose_path(scene_name, im2_name)\n",
    "#     scene_pair_paths.append((path1, path2))\n",
    "\n",
    "# from shutil import copyfile\n",
    "# import subprocess\n",
    "\n",
    "# base_path = \"/home/konstantin/datasets/MegaDepthDataset/test_colmap\"\n",
    "\n",
    "# if not os.path.exists(base_path):\n",
    "#     os.mkdir(base_path)\n",
    "\n",
    "# reconstruction_paths = []\n",
    "\n",
    "# ",
    "# for pair in scene_pair_paths[:50]:\n",
    "#     im1_name = pair[0].split('/')[-1]\n",
    "#     im2_name = pair[1].split('/')[-1]\n",
    "    \n",
    "#     pair_name = im1_name.split('.')[0] + \"_and_\" + im2_name.split('.')[0]\n",
    "    \n",
    "#     pair_folder = os.path.join(base_path, pair_name)\n",
    "    \n",
    "#     if not os.path.exists(pair_folder):\n",
    "#         os.mkdir(pair_folder)\n",
    "        \n",
    "#     images_folder =  os.path.join(pair_folder, \"images\")\n",
    "    \n",
    "#     if not os.path.exists(images_folder):\n",
    "#         os.mkdir(images_folder)\n",
    "    \n",
    "#     p1 = os.path.join(images_folder, im1_name)\n",
    "#     p2 = os.path.join(images_folder, im2_name)\n",
    "    \n",
    "#     copyfile(pair[0], p1)\n",
    "#     copyfile(pair[1], p2)\n",
    "    \n",
    "#     reconstruction_paths.append(pair_folder)\n",
    "\n",
    "# for path in reconstruction_paths:\n",
    "#     print(subprocess.check_output([\"/usr/bin/colmap\", 'automatic_reconstructor', \n",
    "#                      '--workspace_path', path,\n",
    "#                      '--image_path', f'{path}/images',\n",
    "#                      '--use_gpu', \"0\"]))\n",
    "    \n",
    "#     sparse_path = os.path.join(path, 'sparse/0')\n",
    "    \n",
    "#     if os.path.exists(sparse_path):\n",
    "#         sparse_txt_path = os.path.join(path, 'sparse-txt')\n",
    "\n",
    "#         if not os.path.exists(sparse_txt_path):\n",
    "#             os.mkdir(sparse_txt_path)\n",
    "\n",
    "#         print(subprocess.check_output([\n",
    "#             \"/usr/bin/colmap\", 'model_converter',\n",
    "#             '--input_path', sparse_path,\n",
    "#             '--output_path', sparse_txt_path,\n",
    "#             '--output_type', 'TXT'\n",
    "#         ]))\n",
    "    # import torch\n",
    "# import numpy as np\n",
    "\n",
    "# from Net.source.utils.metric_utils import get_gt_poses\n",
    "# from Net.source.utils.math_utils import angle_between_matrices, angle_between_vectors\n",
    "\n",
    "# def compressed_to_pose(compressed_pose):\n",
    "#     qvec = compressed_pose[: 4]\n",
    "#     qvec = qvec / np.linalg.norm(qvec)\n",
    "#     w, x, y, z = qvec\n",
    "#     R = np.array([\n",
    "#         [\n",
    "#             1 - 2 * y * y - 2 * z * z,\n",
    "#             2 * x * y - 2 * z * w,\n",
    "#             2 * x * z + 2 * y * w\n",
    "#         ],\n",
    "#         [\n",
    "#             2 * x * y + 2 * z * w,\n",
    "#             1 - 2 * x * x - 2 * z * z,\n",
    "#             2 * y * z - 2 * x * w\n",
    "#         ],\n",
    "#         [\n",
    "#             2 * x * z - 2 * y * w,\n",
    "#             2 * y * z + 2 * x * w,\n",
    "#             1 - 2 * x * x - 2 * y * y\n",
    "#         ]\n",
    "#     ])\n",
    "#     t = compressed_pose[4: 7]\n",
    "    \n",
    "#     current_pose = np.zeros([4, 4])\n",
    "#     current_pose[: 3, : 3] = R\n",
    "#     current_pose[: 3, 3] = t\n",
    "#     current_pose[3, 3] = 1\n",
    "    \n",
    "#     return current_pose\n",
    "\n",
    "# net_localized = 0\n",
    "# colmap_localized = 0\n",
    "\n",
    "# for path, data in zip(reconstruction_paths, log.filtered_data[:50]):\n",
    "#     gt_rel_pose, est_rel_pose = data[-2:]\n",
    "    \n",
    "#     images_path = os.path.join(path, 'sparse-txt', 'images.txt')\n",
    "    \n",
    "#     if os.path.exists(images_path):    \n",
    "#         with open(images_path, 'r') as f:\n",
    "#             raw = f.readlines()[4:]\n",
    "            \n",
    "#         poses = []\n",
    "        \n",
    "#         for idx, image in enumerate(raw[:: 2]):\n",
    "#             image = image.split(' ')\n",
    "#             poses.append(compressed_to_pose([float(elem) for elem in image[1: -2]]))\n",
    "        \n",
    "#         colmap_rel_pose = get_gt_poses(torch.tensor(poses[0]).unsqueeze(0), \n",
    "#                                        torch.tensor(poses[1]).unsqueeze(0))[0]\n",
    "        \n",
    "#         R_err = angle_between_matrices(colmap_rel_pose[:3, :3], gt_rel_pose[:3, :3].cpu())\n",
    "#         t_err = angle_between_vectors(colmap_rel_pose[:3, 3], gt_rel_pose[:3, 3].cpu())\n",
    "        \n",
    "#         if R_err < 2.0 or t_err < 10.0:\n",
    "#             colmap_localized += 1\n",
    "        \n",
    "#         print(f\"Colmap R_err: {R_err}, t_err {t_err}\")\n",
    "#     else:\n",
    "#         print(\"Colmap failed to converge\")\n",
    "        \n",
    "#     R_err = angle_between_matrices(est_rel_pose[0, :3, :3], gt_rel_pose[:3, :3])\n",
    "#     t_err = angle_between_vectors(est_rel_pose[0, :3, 3], gt_rel_pose[:3, 3])\n",
    "    \n",
    "#     if R_err < 2.0 or t_err < 10.0:\n",
    "#         net_localized += 1\n",
    "    \n",
    "#     print(f\"Net R_err: {R_err}, t_err {t_err}\")\n",
    "    \n",
    "#     print(\"-\"*20)\n",
    "# print(f\"Net localized {net_localized} out of 50\")\n",
    "# print(f\"Colmap localized {colmap_localized} out of 50: \")\n",
    "# from Net.source.utils.eval_utils import draw_cv_keypoints, draw_cv_matches, torch2cv, plot_figures\n",
    "\n",
    "# batch_id = -10\n",
    "\n",
    "# cv_s_image1 = torch2cv(log.filtered_data[batch_id]['image1'])\n",
    "# cv_s_image2 = torch2cv(log.filtered_data[batch_id]['image2'])\n",
    "\n",
    "# kp1 = log.filtered_data[batch_id]['kp1']\n",
    "# kp2 = log.filtered_data[batch_id]['kp2']\n",
    "# nn_desc_ids = log.filtered_data[batch_id]['matches']\n",
    "# prop_match_mask = log.filtered_data[batch_id]['match_mask']\n",
    "\n",
    "# cv_matches = draw_cv_matches(cv_s_image1, cv_s_image2, kp1, kp2, nn_desc_ids, \n",
    "#                              prop_match_mask)\n",
    "# plot_figures({\"check\": cv_matches}, 1, 1, (18, 18))\n",
    "# out_path = \"/home/konstantin/personal/Summertime/Net/runs/NetVGG_v2/sample.pkl\"\n",
    "\n",
    "# with open(out_path, 'wb') as f:\n",
    "#     pickle.dump(log.filtered_data, f)\n",
    "\n",
    "# log_correct = log.groupby('scene_name')['r_err'].apply(lambda x: x.le(pose_thresh[thresh_id]).sum()).reset_index(name='correct') \n",
    "# log_total = log.groupby('scene_name')['r_err'].count().reset_index(name='total') \n",
    "# log_unique = log.groupby('scene_name')['image1_name'].nunique().reset_index(name='unique') \n",
    "\n",
    "# from IPython.display import display\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     log_scene = log_correct.merge(log_total, on='scene_name', how='inner')\n",
    "# #     log_scene.to_csv(\"test_scene.csv\")\n",
    "#     display(log_scene)\n",
    "#     print(f\"Precision: {log_correct['correct'].sum() / log_total['total'].sum()}\")\n",
    "\n",
    "# pose_thresh = np.arange(5, 21, 5)\n",
    "# thresh_id = 0\n",
    "\n",
    "# _mAP, _precision = pose_mAP(log['t_err'], pose_thresh, max_angle=180)\n",
    "\n",
    "# plot_pose_precision_thresh_curve(_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
